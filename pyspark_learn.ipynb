{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark-learn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORIlNeS+9zm7kZ8iaG6+gk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivmarchuk/pyspark-learn/blob/main/pyspark_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "vMjWGBMDZKXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.types as t # for data types conversion\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "HH9fN15woQBa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create SparkSession\n",
        "# parameters for connection could be entered (S3, Google Storage etc.)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "k6B46vFGZKZw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SparkSession - in-memory\n",
        "\n",
        "SparkContext\n",
        "\n",
        "Spark UI\n",
        "\n",
        "Version\n",
        "v3.3.0\n",
        "\n",
        "Master\n",
        "local[*]\n",
        "\n",
        "AppName\n",
        "pyspark-shell"
      ],
      "metadata": {
        "id": "tVYvcYTiaFIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read csv to dataframe\n",
        "df = spark.read.format('csv').option('header', 'true').load('/data-for-spark/cars.csv')"
      ],
      "metadata": {
        "id": "oQhdWO_8ZKeW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to look at wide tables\n",
        "df.show(vertical = True) "
      ],
      "metadata": {
        "id": "LIeLEi9WZKgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at columns\n",
        "df.select(F.col('manufacturer_name'), F.col('model_name')).show(10)"
      ],
      "metadata": {
        "id": "K-8MrWTFZKir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter \n",
        "# df\\\n",
        "#   .select('manufacturer_name', 'model_name', 'transmission')\\\n",
        "#   .filter('manufacturer_name = \"Audi\"')\\\n",
        "#   .filter('transmission = \"mechanical\"').show(10)\n",
        "\n",
        "# better filter -> == could be external parameter cand inserted automatically as var \n",
        "df\\\n",
        "  .select('manufacturer_name', 'model_name', 'transmission')\\\n",
        "  .filter(F.col('manufacturer_name') == 'Subaru')\\\n",
        "  .filter(F.col('transmission') == 'mechanical').show(10)"
      ],
      "metadata": {
        "id": "9EX4rUH_ZKk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count \n",
        "from pyspark.sql.functions import countDistinct\n",
        "# df.count() # for all rows \n",
        "# df.distinct().count()\n",
        "df.select(countDistinct(\"manufacturer_name\")).show()"
      ],
      "metadata": {
        "id": "sZ7oymHGZKnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group and order\n",
        "df\\\n",
        "  .groupBy('manufacturer_name')\\\n",
        "  .count()\\\n",
        "  .orderBy(F.col('count').desc()).show(10)"
      ],
      "metadata": {
        "id": "XTWhcSHRZKrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename\n",
        "df\\\n",
        "  .withColumnRenamed('manufacturer_name', 'firm')\\\n",
        "  .select('firm').show(10)"
      ],
      "metadata": {
        "id": "Qc8ynLaVZKuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add column \n",
        "df\\\n",
        "  .withColumn('next_year', F.col('year_produced') + 5)\\\n",
        "  .select('year_produced', 'next_year').show(10)"
      ],
      "metadata": {
        "id": "etJvA6FjZKwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# column types\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "nwKk2FHaZKy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df stats \n",
        "df.select('manufacturer_name', 'year_produced').describe().show()"
      ],
      "metadata": {
        "id": "5Q1snMICZK1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "vUuhciqRiaz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract csv \n",
        "# define metrics \n",
        "# load new csv "
      ],
      "metadata": {
        "id": "q3S08qj2ia19"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main ():\n",
        "  # start spark session\n",
        "  spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "  # df - read\n",
        "  df = spark.read.format('csv').option('header', 'true').load('/data-for-spark/cars.csv')\n",
        "\n",
        "  # output - df \n",
        "  output = (\n",
        "      df\n",
        "      .groupBy('manufacturer_name')\n",
        "      .agg(\n",
        "          F.count('manufacturer_name').alias('firm'),\n",
        "          F.round(F.avg('year_produced')).cast(t.IntegerType()).alias('average_year'),\n",
        "          F.min(F.col('price_usd')).cast(t.FloatType()).alias('min_price'),\n",
        "          F.max(F.col('price_usd')).cast(t.FloatType()).alias('man_price')\n",
        "      )\n",
        "  )\n",
        "\n",
        "  output.write.mode('overwrite'.format('json')).save('/data-for-spark/output_cars.json') # coalesce to define number of partitions in output file [or to define pandas df to have 1 output file if df is not too large]\n"
      ],
      "metadata": {
        "id": "ybuoudQiia4P"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()\n",
        "\n",
        "# stop session\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "dFSx98-nia6i"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create py file with script\n",
        "# 2. venv -> spar-submit script.py (for exact python script)"
      ],
      "metadata": {
        "id": "YEPXKpeJia_W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}